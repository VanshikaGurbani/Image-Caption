# 🌄 True Image Description: Revealing the Narrative Within Every Frame

This repository showcases the source code and documentation for a deep learning-based image captioning project: **True Image Description**. The system is designed to intelligently generate meaningful narratives by analyzing visual content.

## 🧠 Unveiling the Magic

Picture a world where images narrate their own stories. That’s the vision behind **True Image Description**. Utilizing the power of deep learning—specifically Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) models—our system crafts human-like captions that reflect the true meaning of visual scenes.

## 🚀 Key Features

* **Dual-Modal Transformer Architecture:** Our model combines visual and textual modalities using a powerful dual-modal transformer, enabling it to produce captions that are both coherent and context-aware.
* **Inception V3: Feature Extraction Backbone:** We leverage Inception V3, a widely respected CNN architecture, to capture detailed visual features that form the basis for caption generation.
* **MS COCO: Rich Visual Language Dataset:** The model is trained on the MS COCO dataset, a diverse collection of annotated images that helps it learn a broad spectrum of visual vocabulary.
* **BLEU Score Evaluation:** We use BLEU scores to assess the quality of generated captions. Higher scores indicate a better alignment between machine-generated captions and human annotations.

## 📁 Project Structure

* **🧾 Code:** This folder includes all scripts for image captioning—from preprocessing to model training and caption generation.
* **📄 Documentation:** You're looking at it! This README serves as your guide to understanding how the project works and what it accomplishes.
* **🗂️ Dataset:** We use the MS COCO dataset as our training ground to help the model learn and understand visual semantics.

📬 **Contact**  
If you have any questions or want to collaborate, feel free to reach out at: vanshika.gurbani25@gmail.com
